console.log("hyerim");

import express from "express";
import cors from "cors";
import path from "path";
import * as dotenv from "dotenv";
import OpenAI from "openai";

const app = express();
// cors ì„¤ì •
app.use(cors());

//env ì„¤ì •
const __dirname = path.resolve();
dotenv.config({ path: __dirname + "/.env" });

//test API
app.get("/test", async (req, res) => {
  try {
    res.json({ data: "hyerim" });
  } catch (error) {
    console.log(error);
  }
});

//í”„ë¡ íŠ¸ì—ì„œ ë°›ì€ json í˜•íƒœì˜ ë°ì´í„°ë¥¼ ê°ì²´ë¡œ íŒŒì‹±í•˜ì—¬ ì‚¬ìš©
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

app.post("/message", async (req, res) => {
  const message = req.body.message;
  console.log("ðŸš€ ~ app.post ~ message:", message);
  try {
    res.json({
      id: Date.now(),
      message: message,
    });
  } catch (error) {
    console.log(error);
  }
});

// openai ì •ë³´ ì„¤ì •
const OpenAi = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

console.log(process.env.OPENAI_API_KEY);

// ì±—ë´‡ apiì„¤ì •
const initialMessage = (ingredientList) => {
  return [
    {
      role: "system",
      content: `ë‹¹ì‹ ì€ "ë§›ìžˆëŠ” ì‰í”„"ë¼ëŠ” ì´ë¦„ì˜ ì „ë¬¸ ìš”ë¦¬ì‚¬ìž…ë‹ˆë‹¤. ì‚¬ìš©ìžê°€ ìž¬ë£Œ ëª©ë¡ì„ ì œê³µí•˜ë©´, ì²«ë²ˆì§¸ ë‹µë³€ì—ì„œëŠ” ì˜¤ì§ ë‹¤ìŒ ë¬¸ìž¥ë§Œì„ ì‘ë‹µìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì–´ë–¤ ì •ë³´ë„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”: ì œê³µí•´ì£¼ì‹  ìž¬ë£Œ ëª©ë¡ì„ ë³´ë‹ˆ ì •ë§ ë§›ìžˆëŠ” ìš”ë¦¬ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆì„ ê²ƒ ê°™ì•„ìš”. ì–´ë–¤ ì¢…ë¥˜ì˜ ìš”ë¦¬ë¥¼ ì„ í˜¸í•˜ì‹œë‚˜ìš”? ê°„ë‹¨í•œ í•œë¼ ì‹ì‚¬, íŠ¹ë³„í•œ ì €ë… ë©”ë‰´, ì•„ë‹ˆë©´ ê°€ë²¼ìš´ ê°„ì‹ ë“± êµ¬ì²´ì ì¸ ì„ í˜¸ë„ê°€ ìžˆìœ¼ì‹œë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”. ê·¸ì— ë§žì¶° ìµœê³ ì˜ ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!`,
    },
    {
      role: "user",
      content: `ì•ˆë…•í•˜ì„¸ìš”, ë§›ìžˆëŠ” ì‰í”„ë‹˜. ì œê°€ ê°€ì§„ ìž¬ë£Œë¡œ ìš”ë¦¬ë¥¼ í•˜ê³  ì‹¶ì€ë° ë„ì™€ì£¼ì‹¤ ìˆ˜ ìžˆë‚˜ìš”? ì œ ëƒ‰ìž¥ê³ ì— ìžˆëŠ” ìž¬ë£Œë“¤ì€ ë‹¤ìŒê³¼ ê°™ì•„ìš”: ${ingredientList
        .map((item) => item.value)
        .join(", ")}`,
    },
  ];
};

// ì´ˆê¸° ë‹µë³€
app.post("/recipe", async (req, res) => {
  const { ingredientList } = req.body;
  const messages = initialMessage(ingredientList); //ì‚¬ìš©ìžë¡œë¶€í„° ìž¬ë£Œëª©ë¡ì„ ë°›ì•„ì˜´
  try {
    //OpenAIì—ê²Œ ìš”ì²­ì„ ë³´ëƒ„
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages, //key = value ê°™ë‹¤ë©´ í•˜ë‚˜ë¡œ ì¶•ì•½ê°€ëŠ¥
      temperature: 1,
      max_tokens: 4000,
      top_p: 1,
    });
    const data = [...messages, response.choices[0].message];
    console.log("data", data);
    res.json({ data });
  } catch (error) {
    console.log(error);
  }
});

// ìœ ì €ì™€ì˜ ì±„íŒ…
app.post("/message", async function (req, res) {
  const { userMessage, messages } = req.body;

  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [...messages, userMessage], //ê¸°ì¡´ë©”ì„¸ì§€ì™€ í˜„ìž¬ ìž…ë ¥í•œ ë©”ì„¸ì§€ê°€ì§€ í•œêº¼ë²ˆì— ë³´ë‚¸ë‹¤.ê·¸ëž˜ì„œ ì´ì „ ê¸°ì–µìœ¼ë¡œ ëŒ€í™”ê°€ ê°€ëŠ¥
      temperature: 1,
      max_tokens: 4000,
      top_p: 1,
    });
    const data = response.choices[0].message;
    res.json({ data });
  } catch (error) {
    console.log(error);
  }
});

const port = process.env.PORT || 8081;

// app.listen(8081, () => {
//   console.log("port", port);
// });

app.listen(port);
